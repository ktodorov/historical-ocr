{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\r\n",
    "from gensim.models import Word2Vec\r\n",
    "\r\n",
    "import os\r\n",
    "import re\r\n",
    "import string\r\n",
    "\r\n",
    "from nltk.tokenize import RegexpTokenizer\r\n",
    "\r\n",
    "import sys\r\n",
    "sys.path.insert(0, '..')\r\n",
    "\r\n",
    "from enums.language import Language\r\n",
    "from enums.configuration import Configuration\r\n",
    "from enums.ocr_output_type import OCROutputType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\r\n",
    "\r\n",
    "def get_folder_paths(language: Language):\r\n",
    "    newseye_path = os.path.join('..', 'data', 'newseye')\r\n",
    "\r\n",
    "    result = None\r\n",
    "    if language == Language.English:\r\n",
    "        icdar_2017_1_path = os.path.join(newseye_path, '2017', 'full', 'eng_monograph')\r\n",
    "        icdar_2017_2_path = os.path.join(newseye_path, '2017', 'full', 'eng_periodical')\r\n",
    "        icdar_2019_path = os.path.join(newseye_path, '2019', 'full', 'EN')\r\n",
    "        result = [icdar_2017_1_path, icdar_2017_2_path, icdar_2019_path]\r\n",
    "    elif language == Language.Dutch:\r\n",
    "        icdar_2019_path = os.path.join(newseye_path, '2019', 'full', 'NL', 'NL1')\r\n",
    "        result = [icdar_2019_path]\r\n",
    "\r\n",
    "    return result\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_documents(tokenizer, language: Language, ocr_output_type: OCROutputType):\r\n",
    "    documents = []\r\n",
    "\r\n",
    "    folder_paths = get_folder_paths(language)\r\n",
    "    for folder_path in folder_paths:\r\n",
    "        for filename in os.listdir(folder_path):\r\n",
    "            file_path = os.path.join(folder_path, filename)\r\n",
    "            with open(file_path, 'r', encoding='utf-8') as text_file:\r\n",
    "                file_lines = text_file.readlines()\r\n",
    "                gt_line = file_lines[2] if ocr_output_type == OCROutputType.GroundTruth else file_lines[1]\r\n",
    "                processed_line = gt_line[14:].replace('#', '').replace('@', '')\r\n",
    "\r\n",
    "                text_nonum = re.sub(r'\\d+', '', processed_line)\r\n",
    "                text_nopunct = \"\".join([char.lower() for char in text_nonum if char not in string.punctuation])\r\n",
    "                text_no_doublespace = re.sub('\\s+', ' ', text_nopunct).strip()\r\n",
    "                result = tokenizer.tokenize(text_no_doublespace)\r\n",
    "                documents.append(result)\r\n",
    "\r\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path(language: Language, configuration: Configuration, randomly_initialized: bool, ocr_output_type: OCROutputType):\r\n",
    "    rnd_suffix = 'random' if randomly_initialized else 'pretr'\r\n",
    "\r\n",
    "    model_name = f'gensim_{language.value}_{configuration.value}_{rnd_suffix}_{ocr_output_type.value}.model'\r\n",
    "\r\n",
    "    results_folder = 'results'\r\n",
    "    if not os.path.exists(results_folder):\r\n",
    "        os.mkdir(results_folder)\r\n",
    "\r\n",
    "    result = os.path.join(results_folder, model_name)\r\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\r\n",
    "    if not os.path.exists(model_path):\r\n",
    "        return None\r\n",
    "\r\n",
    "    model = Word2Vec.load(model_path)\r\n",
    "    return model\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec_model_info(language: Language):\r\n",
    "    if language == Language.English:\r\n",
    "        return 'GoogleNews-vectors-negative300.bin', True\r\n",
    "    elif language == Language.Dutch:\r\n",
    "        return 'combined-320.txt', False\r\n",
    "    elif language == Language.French:\r\n",
    "        return 'frwiki_20180420_300d.txt', False\r\n",
    "    elif language == Language.German:\r\n",
    "        return 'dewiki_20180420_300d.txt', False\r\n",
    "\r\n",
    "    error_message = 'Unsupported word2vec language'\r\n",
    "    raise Exception(error_message)\r\n",
    "\r\n",
    "def get_pretrained_matrix(language: Language):\r\n",
    "    data_path = os.path.join('..', 'data', 'ocr-evaluation', 'word2vec', language.value)\r\n",
    "    word2vec_model_name, word2vec_binary = get_word2vec_model_info(language)\r\n",
    "    word2vec_model_path = os.path.join(data_path, word2vec_model_name)\r\n",
    "    word2vec_weights  = gensim.models.KeyedVectors.load_word2vec_format(word2vec_model_path, binary=word2vec_binary)\r\n",
    "    return word2vec_weights, word2vec_model_path, word2vec_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\r\n",
    "\r\n",
    "def create_model(corpus, model_path: str, configuration: Configuration, randomly_initialized: bool, language: Language):\r\n",
    "    sg = 1 if configuration == Configuration.SkipGram else 0\r\n",
    "    vector_size = 320 if language == Language.Dutch else 300\r\n",
    "\r\n",
    "    # initialize the model\r\n",
    "    model = Word2Vec(vector_size=vector_size, window=5, min_count=5, workers=2, sg=sg)\r\n",
    "\r\n",
    "    if not randomly_initialized:\r\n",
    "        word2vec_weights, word2vec_model_path, word2vec_binary = get_pretrained_matrix(language)\r\n",
    "        model.build_vocab([list(word2vec_weights.key_to_index.keys())], update=True)\r\n",
    "        model.intersect_word2vec_format(word2vec_model_path, binary=word2vec_binary, lockf=1.0)\r\n",
    "\r\n",
    "    # build the vocabulary\r\n",
    "    model.build_vocab(corpus, progress_per=1000)\r\n",
    "\r\n",
    "    # train the model\r\n",
    "    model.train(corpus, total_examples=model.corpus_count, epochs=300, report_delay=1)\r\n",
    "\r\n",
    "    # save the model\r\n",
    "    model.save(model_path)\r\n",
    "\r\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language = Language.Dutch\r\n",
    "# configuration = Configuration.SkipGram\r\n",
    "# randomly_initialized = False\r\n",
    "# ocr_output_type = OCROutputType.GroundTruth\r\n",
    "\r\n",
    "for language in [Language.English]:#, Language.English]:\r\n",
    "    for configuration in [Configuration.SkipGram]:#, Configuration.CBOW]:\r\n",
    "        for randomly_initialized in [False]:#, True]:\r\n",
    "            for ocr_output_type in [OCROutputType.GroundTruth]:#, OCROutputType.Raw]:\r\n",
    "                print(f'Training: [\\'{language.value}\\', {configuration.value}, {randomly_initialized}, {ocr_output_type.value}]')\r\n",
    "                documents = read_documents(tokenizer, language, ocr_output_type)\r\n",
    "                model_path = get_model_path(language, configuration, randomly_initialized, ocr_output_type)\r\n",
    "                model = load_model(model_path)\r\n",
    "                if model is None:\r\n",
    "                    print('Model is not loaded. Creating and training now...')\r\n",
    "                    model = create_model(documents, model_path, configuration, randomly_initialized, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_words = {\r\n",
    "#     Language.English: ['man', 'new', 'time', 'day', 'good', 'old', 'little', 'one', 'two', 'three'],\r\n",
    "#     Language.Dutch: ['man', 'jaar', 'tijd', 'dag', 'huis', 'dier', 'werk', 'naam', 'groot', 'kleine', 'twee', 'drie', 'vier', 'vijf']\r\n",
    "# }\r\n",
    "\r\n",
    "# for word in target_words[language]:\r\n",
    "#     print(f'-- \\'{word}\\':')\r\n",
    "#     print(model.wv.most_similar(positive=[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('ocr-uva': conda)",
   "name": "python392jvsc74a57bd0cc29f658ddb1b0f0a648f4c47acf5938bc6d1ad3f68ae93354e191176a755a49"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}