{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import re\r\n",
    "import string\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "from tqdm import tqdm\r\n",
    "from asrtoolkit import wer, cer\r\n",
    "\r\n",
    "import _pickle as pickle\r\n",
    "\r\n",
    "import sys\r\n",
    "sys.path.insert(0, '..')\r\n",
    "\r\n",
    "from enums.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_paths():\r\n",
    "    newseye_path = os.path.join('..', 'data', 'newseye')\r\n",
    "\r\n",
    "    icdar_2017_path = os.path.join(newseye_path, '2017', 'full')\r\n",
    "    icdar_2019_path = os.path.join(newseye_path, '2019', 'full')\r\n",
    "\r\n",
    "    result = {\r\n",
    "        Language.English: [\r\n",
    "            os.path.join(icdar_2017_path, 'eng_monograph'),\r\n",
    "            os.path.join(icdar_2017_path, 'eng_periodical'),\r\n",
    "            os.path.join(icdar_2019_path, 'EN')\r\n",
    "        ],\r\n",
    "        Language.Dutch: [\r\n",
    "            os.path.join(icdar_2019_path, 'NL', 'NL1')\r\n",
    "        ],\r\n",
    "        Language.French: [\r\n",
    "            os.path.join(icdar_2017_path, 'fr_monograph'),\r\n",
    "            os.path.join(icdar_2017_path, 'fr_periodical'),\r\n",
    "            os.path.join(icdar_2019_path, 'FR', 'FR1'),\r\n",
    "            os.path.join(icdar_2019_path, 'FR', 'FR2'),\r\n",
    "            os.path.join(icdar_2019_path, 'FR', 'FR3'),\r\n",
    "        ],\r\n",
    "        Language.German: [\r\n",
    "            os.path.join(icdar_2019_path, 'DE', 'DE1'),\r\n",
    "            os.path.join(icdar_2019_path, 'DE', 'DE2'),\r\n",
    "            os.path.join(icdar_2019_path, 'DE', 'DE3'),\r\n",
    "            os.path.join(icdar_2019_path, 'DE', 'DE4'),\r\n",
    "            os.path.join(icdar_2019_path, 'DE', 'DE5'),\r\n",
    "            os.path.join(icdar_2019_path, 'DE', 'DE6'),\r\n",
    "            os.path.join(icdar_2019_path, 'DE', 'DE7'),\r\n",
    "        ]\r\n",
    "    }\r\n",
    "\r\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cache(cache_filepath, cache_obj):\r\n",
    "    with open(cache_filepath, 'wb') as cache_file:\r\n",
    "        pickle.dump(cache_obj, cache_file)\r\n",
    "\r\n",
    "def calculate_error_rates(specific_language: Language = None):\r\n",
    "    result = {}\r\n",
    "\r\n",
    "    paths_by_language = get_folder_paths()\r\n",
    "\r\n",
    "    for language, folder_paths in paths_by_language.items():\r\n",
    "        if specific_language is not None and language != specific_language: continue\r\n",
    "\r\n",
    "        paths = []\r\n",
    "        for folder_path in folder_paths:\r\n",
    "            for filename in os.listdir(folder_path):\r\n",
    "                file_path = os.path.join(folder_path, filename)\r\n",
    "                paths.append(file_path)\r\n",
    "\r\n",
    "        result[language] = {\r\n",
    "            'wer': np.zeros(len(paths)),\r\n",
    "            'cer': np.zeros(len(paths))\r\n",
    "        }\r\n",
    "\r\n",
    "        result[language]['wer'].fill(-1)\r\n",
    "        result[language]['cer'].fill(-1)\r\n",
    "\r\n",
    "        cache_filepath = os.path.join('results', f'errors_cache_{language.value}.pickle')\r\n",
    "        if os.path.exists(cache_filepath):\r\n",
    "            with open(cache_filepath, 'rb') as cache_file:\r\n",
    "                cache = pickle.load(cache_file)\r\n",
    "        else:\r\n",
    "            cache = result[language]\r\n",
    "\r\n",
    "        for i, file_path in enumerate(tqdm(paths, desc=f'Computing \\'{language.value}\\'', total=len(paths))):\r\n",
    "            with open(file_path, 'r', encoding='utf-8') as text_file:\r\n",
    "                if cache['wer'][i] != -1:\r\n",
    "                    result[language]['wer'][i] = cache['wer'][i]\r\n",
    "                    result[language]['cer'][i] = cache['cer'][i]\r\n",
    "                    continue\r\n",
    "\r\n",
    "                file_lines = text_file.readlines()\r\n",
    "                gt_line = file_lines[2][14:]\r\n",
    "                ocr_line = file_lines[1][14:]\r\n",
    "\r\n",
    "                n = 500\r\n",
    "                if len(gt_line) > n:\r\n",
    "                    gt_chunks = [gt_line[i:i+n] for i in range(0, len(gt_line), n)]\r\n",
    "                    ocr_chunks = [ocr_line[i:i+n] for i in range(0, len(ocr_line), n)]\r\n",
    "\r\n",
    "                    temp_wer = []\r\n",
    "                    temp_cer = []\r\n",
    "                    for gt_chunk, ocr_chunk in zip(gt_chunks, ocr_chunks):\r\n",
    "                        temp_wer.append(wer(gt_chunk, ocr_chunk))\r\n",
    "                        temp_cer.append(cer(gt_chunk, ocr_chunk))\r\n",
    "\r\n",
    "                        result[language]['wer'][i] = np.mean(temp_wer)\r\n",
    "                        result[language]['cer'][i] = np.mean(temp_cer)\r\n",
    "                else:\r\n",
    "                    result[language]['wer'][i] = wer(gt_line, ocr_line)\r\n",
    "                    result[language]['cer'][i] = cer(gt_line, ocr_line)\r\n",
    "\r\n",
    "                if i % 10 == 0:\r\n",
    "                    save_cache(cache_filepath, cache)\r\n",
    "\r\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing 'english': 100%|██████████| 963/963 [00:21<00:00, 44.30it/s]\n",
      "Computing 'dutch': 100%|██████████| 150/150 [00:02<00:00, 51.79it/s]\n",
      "Computing 'french': 100%|██████████| 3993/3993 [01:30<00:00, 44.06it/s]\n",
      "Computing 'german': 100%|██████████| 10032/10032 [02:39<00:00, 62.85it/s]\n"
     ]
    }
   ],
   "source": [
    "error_rates_per_language = calculate_error_rates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english WER: 38.453125273560005\n",
      "english CER: 84.58698025710028\n",
      "dutch WER: 183.04292156823422\n",
      "dutch CER: 662.2354336199279\n",
      "french WER: 17.437550110440373\n",
      "french CER: 39.91430664575433\n",
      "german WER: 77.19739226912753\n",
      "german CER: 28.980495066405396\n"
     ]
    }
   ],
   "source": [
    "for language, error_rates in error_rates_per_language.items():\r\n",
    "    print(f'{language.value} WER: {error_rates[\"wer\"].mean()}')\r\n",
    "    print(f'{language.value} CER: {error_rates[\"cer\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105.0894524296487"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rates_per_language[Language.Dutch]['cer'][2]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc29f658ddb1b0f0a648f4c47acf5938bc6d1ad3f68ae93354e191176a755a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('ocr-uva': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}